{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa prática, iremos entender melhor o conceito de Overfitting e underfitting além de ter o primeiro contato com um método de aprendizado de máquina supervisionado (Árvore de Decisão). Para isso, iremos usar a biblioteca [Scikit Learn](ttps://scikit-learn.org), além das bibliotecas que usamos na prática passada: pandas, matplotlib e numpy. Clique no código abaixo e pressione ctrl+enter para executá-lo.\n",
    "\n",
    "Para isso, se necessário, instale tais bibliotecas usando `pip3 install pandas matplotlib numpy` (em alguns Sistemas Operacionais/configurações, você usará `pip` ao inves de `pip3`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting - Exemplo Ilustrativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A principio, vamos fazer um dataset artificial em que possuimos dois atributos (também chamado de caracteríscas ou, do inglês, *features*) e duas possíveis saídas (também chamado de valor alvo ou classe alvo). Para isso, temos a matriz `x` e o vetor `y` em que, para cada exemplo `i`, cada linha `x[i]` dessa matriz representa esse exemplo (neste caso, representado por dois atributos) e a classe alvo `y[i]`.\n",
    "\n",
    "Veja o dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "x, y = sklearn.datasets.make_moons(400, noise=0.25)\n",
    "x[:10]#10 primeiras linhas da matriz X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:10]#lista com 10 primeiros itens do vetor y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa e nas demais práticas, iremos representar a classe alvo como um vetor `y` e, os atributos, pela matriz `x`.\n",
    "\n",
    "Abaixo, podemos ver a representação gráfica deste dataset em que, para cada instancia `i`, o eixo x é o atributo `x[i][0]` e o eixo y é o atributo `x[i][1]` a classe alvo `y[i]` é representada pela cor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(x[:,0], x[:,1], s=40, c=y, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente, no aquivo `arvore_de_decisao.py` implemente a função `cria_modelo`. Veja a seguir as instruções de como implementá-la.\n",
    "\n",
    "Nessa função, você deverá criar um modelo baseado em arvore de decisão, por meio de um treino. Para o treino, use a variável `x` (que pode ser uma matriz ou DataFrame) em que, cada linha, é uma instância representada pelos seus atributos, além disso, a `y` é um vetor ou Series  representando a classe alvo  de cada instância. Coloque como `random_state=1` que é o seed (semente) da função aleatória usada, pois, por padrão, a árvore de decisão do Scikit learn obtém os dados de forma aleátoria. Definindo este parametro, garantimos que o resultado será o mesmo em todas as execuções.\n",
    "\n",
    "Além disso, com o objetivo de avaliarmos o overfitting, essa função possuirá o parametro `min_samples_split` que \n",
    " que define o mínimo de exemplos necessários para que um nodo da árvore efetue a divisão. Use esse parâmetro ao instanciar a Árvore de Decisão. \n",
    "\n",
    "Para implementar essa função, use a classe `DecisionTreeClassifier`. [Veja a documentação desta classe](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). Se necessário, comente a importação abaixo, copie e cole a função aqui e, logo após, volte ela para o arquivo. Para criar/obter o modelo use o [método fit](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.fit).  Após implementar, execute o teste abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m tests TestDecisionTree.test_cria_modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logo após, execute o código abaixo para importar a função criada. Lembre-se de reiniciar o kernel caso faça alguma modificação na mesma após importar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arvore_decisao import cria_modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, crie um modelo e use a função `plot_decision_boudary` para gerar o grafico apresentado o dataset ilustrativo com a superfície de decisão do modelo criado. Essa função está no arquivo `util.py`.\n",
    "\n",
    "Na criação do modelo, altere o parametro `min_samples` até um valor que você julgue adequado. Veja o *overfitting* em valores muito baixos (abaixo de 1%, principalmente) e *underfitting* em valores muito altos. Como usualmente implementada, a porcentagem nesta função é um valor entre 0 e 1 em que 1 representa 100% 0.5, por exemplo, representa 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from util import plot_decision_boundary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impacto do Overfitting/Underfitting - Estimativa Automática da Qualidade de Conteúdo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta prática, iremos usar dados de 3.294 artigos da Wikipédia rotulados manualmente quanto a sua qualidade. \n",
    "\n",
    "Esses artigos passaram por uma avaliação pela comunidade de editores da Wikipedia. Tais editores classificaram esses artigos quanto a qualidade da seguinte forma: \n",
    "\n",
    "- **Artigo Destaque (FA)**: Os artigos atribuídos a esta classe são, de acordo com os avaliadores, os melhores artigos da Wikipédia.\n",
    "- **Classe A (AC)**: os artigos da Classe A são considerados completos, mas com alguns problemas pendentes que precisam ser resolvidos para serem promovidos a Artigos em destaque.\n",
    "- **Artigo Bons (GA)**: Bons Artigos são aqueles sem problemas de lacunas ou conteúdo excessivo. Essas são boas fontes de informação, embora outras enciclopédias possam fornecer um conteúdo melhor.\n",
    "- **Classe B (BC)**: os artigos atribuídos a essa classe são considerados úteis para a maioria dos usuários, mas carecem de informações mais precisas.\n",
    "- **Classe Inicial (ST)**: os artigos da Classe Inicial ainda estão incompletos, embora contenham referências e ponteiros para informações mais completas.\n",
    "- **Artigos Rascunhos (SB)**: os artigos de toco são artigos de rascunho, com poucos parágrafos. Eles também têm poucas ou nenhumas citações.\n",
    "\n",
    "Assim, [Dalip et. al. (2009)](https://dl.acm.org/citation.cfm?id=1555449) fizeram o preprocessamento desses artigos para serem extraídos indicadores de qualidades tais como: idade do artigo, tamanho, número de citações. Com tais indicadores e a classe de qualidade, foi possível realizar a predição automática de qualidade de artigos da Wikipédia.\n",
    "\n",
    "Nesta prática, iremos fazer a previsão da qualidade usando os indicadores proposto por [Dalip et. al. (2009)](https://dl.acm.org/citation.cfm?id=1555449) e uma árvore de decisão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente, uso um DataFrame pandas e [leia o arquivo `wikipedia.csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) e exiba os dados deste dataset. Coloque como o rótulo da linha o id do artigo (ou seja, no dataset, a coluna `id` será a `index_col` do DataFrame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de executar a classificação e verificar o acerto no treino e teste, você deverá implementar a função `divide_treino_teste` que está no arquivo `arvore_decisao.py`.\n",
    "\n",
    "Essa função deverá dividir os dados, de forma aleatoria, em treino e teste.  Para isso, faça o seguinte: \n",
    "\n",
    "1. Crie o DataFrame `df_treino` por meio do Dataframe `df` e a proporção `val_proporcao_treino`, passados como parâmetro. `val_proporcao_treino` assume um valor de 0 a 1 em que, por exemplo, 0.8 representa que 80% das instancias serão de treino e, o restante, o teste. . O [método `sample`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html) irá auxiliar para isso. Us, como parâmetro `random_state=1`. Esse será o valor da semente (seed) da função aleatória para manter sempre os dados embaralhados da mesma forma (o teste unitário só irá funcionar caso tenha colocado a esse valor de semente);\n",
    "\n",
    "2. Conforme dito, o restante das instancias estarão em `df_teste`. Uma forma fácil de criar o `df_teste` é obter os elementos que estão em `df` e não estão em `df_treino`. Para isso, use [o método `drop`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html) que elimina conlunas ou  linhas de um DataFrame. Para eliminar as linhas, obtenha o id de cada linha do treino usando `df_treino.index`.\n",
    "\n",
    "Em Python uma função pode retornar mais de um elemento. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xuxu():\n",
    "    a = 2\n",
    "    b = 3\n",
    "    return a,b\n",
    "x,y = xuxu()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute o seguinte testa para verificar a corretude de seu código: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m tests TestDecisionTree.test_divide_treino_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, execute a função `divide_treino_teste` com uma divisão de 80% de treino e, logo após, usando df_treino e df_teste, crie as seguintes variáveis:\n",
    "-  `x_treino` : DataFrame que representa, para cada linha do **treino**, todos os atributos de um exemplo do treino. Para isso, elimine a coluna que representa a classe por meio [método `drop` do DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html), alterando o parametro axis;\n",
    "- `y_treino`: Series que representa, para cada posição `i`, a classe alvo do exemplo `i` representado pelos atributos `x_treino[i]`. A classe alvo está na coluna `realClass`;\n",
    "- `x_teste`: Similar ao `x_teste`, porém com as instancias do **teste**. \n",
    "- `y_teste`: Similar ao `y_treino`, porém, são as classe alvo do teste; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arvore_decisao import divide_treino_teste\n",
    "\n",
    "#execute a função divide_treino_teste corretamente\n",
    "df_treino, df_teste = None\n",
    "\n",
    "#instancias de treino - separe as features x da classe y\n",
    "x_treino = None\n",
    "y_treino = None\n",
    "\n",
    "\n",
    "#instancias de teste - separe as features x da classe y\n",
    "x_teste =  None\n",
    "y_teste = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemente agora o método `faz_classificacao`. Ele passará como parametro as variáveis `X_treino`, `y_treino`, `X_teste`, `y_teste`, criadas anteriormente além do parâmetro `min_samples` que define a quantidade mínima de instancias para que se divida um nodo da árvore de decisão.\n",
    "\n",
    "Assim, esta função irá:\n",
    "\n",
    "1- Criar o modelo a partir dos dados de treino e o parametro `min_samples` (você pode usar a função criada anteriormente);\n",
    "\n",
    "2- Realizar a predição usando o [método predict](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.predict). Esse método retorna uma lista de predição em que, para cada posição `i`, retorna o resultado previsto do exemplo representado por `x_teste[i]`;\n",
    "\n",
    "3- A partir da lista obtida pela predição e da variável `y_teste`, calcule a `acuracia` que é a proporção de acertos, ou seja, $acuracia = acertos/|y_{teste}|$ em que `acertos` é a quantidade de acertos da predição e $y_{teste}$ é a lista `y_teste`.\n",
    "\n",
    "Dicas:\n",
    "- caso tenhamos duas listas `a` e `b`, ao fazer a operação `a==b`, ele retornará uma lista em que o valor  de cada posição será igual a verdadeiro caso `a==b`.\n",
    "- np.sum soma os valores de um vetor, caso os valores sejam booleanos, será considerado True=1 e False=0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logo após, execute o teste abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m tests TestDecisionTree.test_faz_classificacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arvore_decisao import faz_classificacao\n",
    "y_predicted,acuracia =  None\n",
    "\n",
    "print(\"Acurácia: {0}\".format(acuracia)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por meio da função `plot_performance_min_samples` crie um gráfico em que o eixo `x` é a variação do parâmetro `min_samples` e, o eixo `y`, representará a acurácia. Você deverá veriar o `min_samples` de 0.001 até 0.7 de 0.01 em 0.01 passos. Esse gráfico possuirá duas linhas: representando a **acurácia no treino** durante a variação do `min_samples` e, a outra, a **acurácia do teste** com os diversos valores de `min_sample`.\n",
    "\n",
    "- foi usada a função arange do numpy para o for (ao invés de range). Pois o range permite apenas passos com valores inteiros;\n",
    "- para obter a acurácia no treino, o teste deverá possuir as mesmas instancias do treino;\n",
    "- Para plotar foi usado o matplotlib veja: [https://matplotlib.org/users/pyplot_tutorial.html](https://matplotlib.org/users/pyplot_tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute abaixo a função plot_performance_min_samples usando as veriáveis X_treino,y_treino,X_teste,y_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arvore_decisao import plot_performance_min_samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escreva abaixo **um paragrafo** descrevendo o que pode ser visto no gráfico e quando há overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção! Nesta nossa prática, variamos o parametro no teste para ver o impacto da variável `min_samples_split` no mesmo. Porém,  caso quisessems comparar este classificador com outro, **não devemos usar informação do teste para construir o classificador** pois o teste deve reproduzir \"o mundo real\" e não saberiamos os valores do teste a priori.  \n",
    "\n",
    "Assim, não é metodologicamente correto escolher um parâmetro utilizando do teste. Para resolver esse problema, poderemos ter uma partição de validação. \n",
    "\n",
    "\n",
    "**Opcional**: Divida os dados em 60% de treino, 20% de validação e 20% de teste. Use a partição de validação para descobrir o melhor parametro `min_samples` (melhor=maior acurácia). Por meio dele, treine o modelo e calcule o resultado no teste. Além da acurácia, use a função [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) para exibir outras métricas de avaliação disponíveis no Scikit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Opcional²** Como a qualidade pode ser encarada como uma nota em uma escala, modelar este problema como regressão pode ser melhor. Por isso, use [regressão e RandomForest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) e apresente o [Mean Squared Error](https://en.wikipedia.org/wiki/Mean_squared_error) obtido. Usando o treino e **validação** descubra o melhor valor para `min_samples_split`, apresente o grafico, e use o melhor parametro obtido na validação para o teste."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
